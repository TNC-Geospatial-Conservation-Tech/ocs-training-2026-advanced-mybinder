{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f27871-325c-49ce-bfe4-173a3a13c47b",
   "metadata": {},
   "source": [
    "# Using cloud-native tools to map invasive species with supervised machine learning and Sentinel 2\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Aims\n",
    "\n",
    "This notebook demonstrates a complete end-to-end workflow for mapping invasive species across large geographic areas using cloud-native geospatial tools and supervised machine learning. The specific objectives are:\n",
    "\n",
    "- Learn how to discover and access satellite imagery from cloud-based data repositories using STAC catalogs\n",
    "- Extract spectral information from satellite data at validated field locations\n",
    "- Train a machine learning classifier (XGBoost) to distinguish invasive species from other land cover types\n",
    "- Deploy the trained model efficiently across entire satellite scenes using parallel processing\n",
    "- Generate spatially-explicit predictions of invasive species distribution for conservation planning and monitoring\n",
    "\n",
    "### Structure\n",
    "\n",
    "The notebook is organized into a data pipeline with three main phases:\n",
    "\n",
    "1. **Data Preparation** (Sections 2-5): Load validation data, search for and retrieve Sentinel-2 imagery from AWS, and extract spectral features at known locations\n",
    "2. **Model Development** (Section 6): Train and evaluate an XGBoost classifier on held-out test data\n",
    "3. **Deployment & Export** (Section 7): Apply the trained model across the entire study area using parallel processing and export results as a cloud-optimized GeoTIFF\n",
    "\n",
    "The example focuses on mapping invasive Pine trees in the Greater Cape Town water fund area, demonstrating how these techniques can support conservation monitoring and resource management decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad306b-4bd5-485f-8c79-2703ac06efe9",
   "metadata": {},
   "source": [
    "### 1. Load Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32c6fe-894d-47ba-b86f-ea4bea85d850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#core python geospatial packages\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import rioxarray as riox\n",
    "import geopandas as gpd\n",
    "import xvec\n",
    "from shapely.geometry import box, mapping\n",
    "\n",
    "#data search\n",
    "import stackstac\n",
    "import pystac_client\n",
    "\n",
    "#plotting\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "#interactive plots\n",
    "hvplot.extension('bokeh')\n",
    "\n",
    "#static plots\n",
    "#hvplot.extension('matplotlib')\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#ml\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#other\n",
    "from dask.diagnostics import ProgressBar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dd2f3-91ce-489b-926e-eb0099cd6bec",
   "metadata": {},
   "source": [
    "### 2. Load invasive plant data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f53c4-d5e2-4315-a7d3-7b84bdcd4803",
   "metadata": {},
   "source": [
    "First we load our land cover and invasive plant location data. We create this using field data and/or manually inspected high-resolution imagery. \n",
    "\n",
    "We will use the Python package `geopandas` to handle spatial vector data. GeoPandas is a Python library designed to handle and analyze geospatial data, similar to how ArcGIS or the `sf` package in R work. It extends the popular `pandas` library to support spatial data, allowing you to work with vector data formats like shapefiles, GeoJSON, GeoPackage and more. GeoPandas integrates well with other Python libraries and lets you perform spatial operations like overlays, joins, and buffering in a way that's familiar if you're used to `sf` or ArcGIS workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801050df-39b5-46fc-bde4-4525f9f14d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data in geopackage with geopandas\n",
    "\n",
    "gdf = gpd.read_file('gctwf_invasive.gpkg')\n",
    "gdf = gdf.to_crs(\"EPSG:32734\")\n",
    "bbox = gdf.total_bounds\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5c48",
   "metadata": {},
   "source": [
    "#### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive plot\n",
    "gdf[['name','geometry']].explore('name',tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710c494-a4e1-4b57-9eae-060f8816755d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We will need this later to turn codes back to names\n",
    "# Get unique values\n",
    "name_table = gdf[['class', 'name']].drop_duplicates().sort_values(by=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b14016-3a3a-4332-a448-08eb56644b02",
   "metadata": {},
   "source": [
    "### 3. Search for remote sensing data using STAC\n",
    "\n",
    "STAC (SpatioTemporal Asset Catalog) is a standardized specification for describing geospatial datasets and their metadata, making it easier to discover, access, and share spatiotemporal data like satellite imagery, aerial photos, and elevation models. STAC catalogs and APIs provide structured, searchable metadata that allow users to query datasets based on criteria like geographic location, time range, resolution, or cloud coverage.\n",
    "\n",
    "On AWS, STAC datasets can be found in the [Registry of Open Data](https://registry.opendata.aws/), which hosts numerous public geospatial datasets in STAC format. Examples include satellite imagery from Landsat, Sentinel-2, and MODIS. You can use tools like the `pystac-client` Python library or STAC browser interfaces to explore and retrieve data directly from AWS S3 buckets.\n",
    "\n",
    "Once we have used STAC to filter the data we want, we get URLs to the location of that data on AWS S3 object storage. If we have our own data directly stored on S3, we can skip this part and just use that URL directly, or we can create our own STAC catalog if we have a large collection of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093695b4-e878-4674-b2ed-df5160e807d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#the location of the catalog we want to search (find this on AWS Registry of Open Data)\n",
    "URL = \"https://earth-search.aws.element84.com/v1\"\n",
    "catalog = pystac_client.Client.open(URL)\n",
    "\n",
    "#we want data that intersect with this location\n",
    "lat, lon = -33.80, 19.20\n",
    "#in this time\n",
    "datefilter = \"2018-09-01/2018-09-30\"\n",
    "\n",
    "#search!\n",
    "items = catalog.search(\n",
    "    intersects=dict(type=\"Point\", coordinates=[lon, lat]),\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=datefilter,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 10}}  # Filter for cloud cover less than 10%\n",
    ").item_collection()\n",
    "\n",
    "#how many matches?\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193cf1b-d9e2-4f78-998d-d38395de9324",
   "metadata": {},
   "source": [
    "Let's print some info about this Sentinel-2 scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f0b0e-3b11-49e2-860d-4b90807329c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f8ca0-0774-4c09-a466-419cd875a660",
   "metadata": {},
   "source": [
    "### 4. Load our data\n",
    "\n",
    "Now that we have the data we want, we can load it into an xarray. We could pass the S3 URL of the data directly to xarray, but the package `stackstac` does a bunch of additional data handling to return a neat result with lots of helpful metadata. We can, for example, give `stackstac` a list of multiple Sentinel-2 scenes and it will align and stack them along a time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d582a3-72d3-4553-ba4b-09135da8ec54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack = stackstac.stack(items[0],bounds=(bbox[0], bbox[1], bbox[2], bbox[3]),epsg=32734)\n",
    "\n",
    "#stackstac creates a time dim, but we only have 1 date so we drop this\n",
    "stack = stack.squeeze()\n",
    "\n",
    "#select only the bands we need\n",
    "stack = stack.sel(band=['blue', 'coastal', 'green', 'nir', 'nir08', 'nir09', 'red', 'rededge1', 'rededge2', 'rededge3', 'swir16', 'swir22'])\n",
    "\n",
    "#combine bands into one chunk\n",
    "stack = stack.chunk({'band':-1})\n",
    "\n",
    "#look at the xarray\n",
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f537b4-6284-4d54-87d5-86ebce5471c9",
   "metadata": {},
   "source": [
    "Let's make a plot to see what it looks like in true color. We will use the package `hvplot`, which makes it very easy to create interactive plots from xarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd233627-53de-4eeb-a996-0f1ac02cd25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack.sel(band=['red','green','blue']).hvplot.rgb(\n",
    "    x='x', y='y', bands='band',rasterize=True,robust=True,data_aspect=1,title=\"True colour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b84d80-124f-48c0-8a93-6dd5703de62a",
   "metadata": {},
   "source": [
    "#### Shadow Masking \n",
    "In the image above some areas are shadowed by mountains. It is unlikely that we will be able to predict land cover in these areas, so lets mask them out. We will use a simple rule that says if the reflectance in the red and near-infrared is below a threshold, drop those pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb54f9-3ae4-45e2-b5c7-1fb363c0682e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select red and nir bands\n",
    "red = stack.sel(band='red')\n",
    "nir = stack.sel(band='nir')\n",
    "\n",
    "# Set the reflectance threshold\n",
    "threshold = 0.05\n",
    "\n",
    "# Create a shadow mask: identify dark pixels across all bands\n",
    "shadow_condition = (red < threshold) & (nir < threshold)\n",
    "\n",
    "# Set shadowed pixels to nodata\n",
    "stack = stack.where(~shadow_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfee50-c370-4100-986a-2146793abf10",
   "metadata": {},
   "source": [
    "### 5. Extract Sentinel-2 data at point locations\n",
    "\n",
    "Now we will extract the reflectance data at the locations where we have validated land cover. The package `xvec` makes this easy. It returns the result as an xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067291f-9c6c-4f3a-95e3-9ed68cdd072a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract points\n",
    "point = stack.xvec.extract_points(gdf['geometry'], x_coords=\"x\", y_coords=\"y\",index=True)\n",
    "point = point.swap_dims({'geometry': 'index'}).to_dataset(name='s2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212455d-2d0b-45c7-94c1-d4e1be401455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets actually run this and get the result\n",
    "with ProgressBar():\n",
    "    point = point.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4c97b-d2e3-41f9-8566-d8f2603c58a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop points that contain nodata\n",
    "condition = point.s2.notnull().any(dim='band')\n",
    "\n",
    "# Apply the mask to keep only the valid indices\n",
    "point = point.where(condition, drop=True)\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c6d41-e40a-470e-a30d-a8e70dfc78e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add label from geopandas\n",
    "gxr =gdf[['class','group']].to_xarray()\n",
    "point = point.merge(gxr.astype(int),join='left')\n",
    "point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e499832-5120-439b-90a0-e962f715837e",
   "metadata": {},
   "source": [
    "Let's select a single point and visualize the data we will be using to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec9aa2-1a35-43c1-8fe0-19ae6fc3f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointp = point.isel(index=0)\n",
    "pointp['center_wavelength'] = pointp['center_wavelength'].astype(float)\n",
    "pointp['s2'].hvplot.scatter(x='center_wavelength',by='index',\n",
    "                                         color='green',ylim=(0,0.3),alpha=0.5,legend=False,title = \"Single point data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dfd635",
   "metadata": {},
   "source": [
    "Finally, our model will be trained on data covering natural vegetation in a specific area. It is important that we only predict in the areas that match our training data. We will therefore mask out non-natural vegetation using a polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b04a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf = gpd.read_file('aoi.gpkg').to_crs(\"EPSG:32734\")\n",
    "geoms = geodf.geometry.apply(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ce23b-22a7-453a-b02e-b3b430224ead",
   "metadata": {},
   "source": [
    "### 6. Train ML model\n",
    "We will be using a model called xgboost. There are many, many different kinds of ML models. xgboost is a class of models called gradient boosted trees, related to random forests. When used for classification, random forests work by creating multiple decision trees, each trained on a random subset of the data and features, and then averaging their predictions to improve accuracy and reduce overfitting. Gradient boosted trees differ in that they build trees sequentially, with each new tree focusing on correcting the errors of the previous ones. This sequential approach allows xgboost to create highly accurate models by iteratively refining predictions and addressing the weaknesses of earlier trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc577929-ad00-486e-815c-6a4ddd152725",
   "metadata": {},
   "source": [
    "Our dataset has a label indicating which set (training or test) our data belong to. We will use this to split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b564fc-39dd-41a4-82c8-530e9d95d1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "dtrain = point.where(point['group']==1,drop=True)\n",
    "dtest = point.where(point['group']==2,drop=True)\n",
    "\n",
    "#create separte datasets for labels and features\n",
    "y_train = dtrain['class'].values.astype(int)\n",
    "y_test = dtest['class'].values.astype(int)\n",
    "X_train = dtrain['s2'].values.T\n",
    "X_test = dtest['s2'].values.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce60782e-36c4-4f0a-848a-6b7fe6ebf9e5",
   "metadata": {},
   "source": [
    "To train the model, we:\n",
    "\n",
    "1. Create an XGBoost classifier object using the `XGBClassifier` class from the XGBoost library, specifying a set of reasonable hyperparameters.\n",
    "2. Fit the model to our training data (`X_train` and `y_train`).\n",
    "\n",
    "The model learns to associate spectral signatures with land cover classes, and will then be evaluated on the held-out test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628bddcf-5cf7-4a05-a96e-759834023fa9",
   "metadata": {},
   "source": [
    "We fit the model to our training data (`X_train` and `y_train`). Once training is complete, the model is ready for making predictions on the test set and for deployment across the full study area.\n",
    "\n",
    "This will take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71ec2b-c662-4a50-b919-a60d0ddec905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and train the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    n_estimators=100,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d82332-3914-46f6-a759-d43962de7e4e",
   "metadata": {},
   "source": [
    "We will use our trained model to predict the classes of the test data and calculate accuracy.\n",
    "\n",
    "Next, we assess how well the model performs for predicting Pine trees by calculating its precision and recall. Precision measures the accuracy of the positive predictions. It answers the question, \"Of all the instances we labeled as Pines, how many were actually Pines?\". Recall measures the model's ability to identify all actual positive instances. It answers the question, \"Of all the actual Pines, how many did we correctly identify?\". You may also be familiar with the terms Users' and Producers' Accuracy. Precision = Users' Accuracy, and Recall = Producers' Accuracy.\n",
    "\n",
    "Finally, we create and display a confusion matrix to visualize the model's prediction accuracy across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7dbec-570c-4433-adad-49217073847f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 2: Calculate acc and F1 score for the entire dataset\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "# Step 3: Calculate precision and recall for Pine\n",
    "precision_pine = precision_score(y_test, y_pred, labels=[2], average='macro', zero_division=0)\n",
    "recall_pine = recall_score(y_test, y_pred, labels=[2], average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Precision for Pines: {precision_pine}\")\n",
    "print(f\"Recall for Pines: {recall_pine}\")\n",
    "\n",
    "# Step 4: Plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred,normalize='pred')\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=list(name_table['name'])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca7d032-3335-4221-92b9-54ff4c0118c0",
   "metadata": {},
   "source": [
    "### 7. Predict over entire study area\n",
    "\n",
    "We now have a trained model and are ready to deploy it across an entire Sentinel-2 scene to map the distribution of invasive plants. This involves a large volume of data, so rather than processing it all at once, we will apply the model's `.predict()` method in parallel across manageable chunks of the Sentinel-2 xarray.\n",
    "\n",
    "#### Parallel vs. sequential processing\n",
    "\n",
    "In serial processing, tasks execute one after another, so total runtime is the sum of all steps. In parallel processing, the work is split into independent chunks that run simultaneously across multiple workers, with results combined at the end. This can dramatically reduce processing time — a 3-hour serial job might take roughly 1 hour across 3 workers. Geospatial workflows are naturally suited to this approach because operations on individual tiles or regions are typically independent of one another.\n",
    "\n",
    "![](img/series_parallel.png)\n",
    "\n",
    "#### How parallel processing works with Dask\n",
    "\n",
    "When we loaded our Sentinel-2 data earlier, xarray automatically divided it into smaller pieces called **chunks** — think of them as tiles in a mosaic. Dask, the parallel computing library working behind the scenes, uses these chunks to orchestrate efficient computation.\n",
    "\n",
    "Rather than computing results immediately, Dask builds a **task graph** — a recipe mapping out which operations to perform on which chunks. When we define operations (like applying our model), Dask records the instructions without executing them. Only when we call `.compute()` does Dask execute the graph, processing multiple chunks simultaneously across available CPU cores.\n",
    "\n",
    "![](img/dummy_graph.png)\n",
    "\n",
    "This has two key advantages: (1) we can work with datasets larger than memory because only the active chunks need to be loaded at any given time, and (2) operations run faster because chunks are processed concurrently rather than one at a time.\n",
    "\n",
    "**Monitoring progress with the Dask Dashboard**: You can track the progress of Dask operations in real time using the Dask Dashboard. In Jupyter environments like SageMaker Studio Lab, look for a dashboard link in the output. It displays task execution, memory usage, and worker activity — useful for spotting bottlenecks and confirming your computation is progressing as expected.\n",
    "\n",
    "**Learning more about Dask**: To go deeper, see the [Dask documentation](https://docs.dask.org/) for tutorials on task graphs, distributed computing, and optimization. The [Dask tutorial](https://tutorial.dask.org/) is also an excellent interactive starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5551332-51f1-445b-a1ea-d645930af06a",
   "metadata": {},
   "source": [
    "Here is the function that we will actually apply to each chunk. Simple really. The hard work is getting the data into and out of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2d93a-de7e-48b3-a4af-ddef6960e64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_on_chunk(chunk, model):\n",
    "    probabilities = model.predict_proba(chunk)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40270d-2a10-46cc-8808-0e15ad609bad",
   "metadata": {},
   "source": [
    "Now we define the function that takes as input the Sentinel-2 xarray and passes it to the predict function. This is composed of three parts:\n",
    "\n",
    "**Part 1:** Applies all the transformations that need to be done before the data goes to the model. It sets a condition to identify valid data points where reflectance values are greater than zero and stacks the spatial dimensions (x and y) into a single dimension.\n",
    "\n",
    "**Part 2:** Applies the machine learning model to the data in parallel, predicting class probabilities for each data point using xarray's `apply_ufunc` method. Most of the function involves defining what to do with the dimensions of the old dataset and the new output.\n",
    "\n",
    "**Part 3:** Unstacks the data to restore its original dimensions, sets spatial dimensions and coordinate reference system (CRS), clips the data, and transposes the data to match expected formats before returning the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cff3a-867a-4bca-b1b5-4247b46eeca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_xr(ds,geometries):\n",
    "\n",
    "    #part 1 - data prep\n",
    "    #condition to use for masking no data later\n",
    "    condition = (ds > 0).any(dim='band')\n",
    "\n",
    "    #stack the data into a single dimension. This will be important for applying the model later\n",
    "    ds = ds.stack(sample=('x','y'))\n",
    "\n",
    "\n",
    "    #part 2 - apply the model over chunks\n",
    "    result = xr.apply_ufunc(\n",
    "        predict_on_chunk,\n",
    "        ds,\n",
    "        input_core_dims=[['band']],#input dim with features\n",
    "        output_core_dims=[['class']],  # name for the new output dim\n",
    "        exclude_dims=set(('band',)),  #dims to drop in result\n",
    "        output_sizes={'class': 10}, #length of the new dimension\n",
    "        output_dtypes=[np.float32],\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={'model': model}\n",
    "    )\n",
    "\n",
    "    #part 3 - post-processing\n",
    "    result = result.unstack('sample') #remove the stack\n",
    "    result = result.rio.set_spatial_dims(x_dim='x',y_dim='y') #set the spatial dims\n",
    "    result = result.rio.write_crs(\"EPSG:32734\") #set the CRS\n",
    "    result = result.rio.clip(geometries).where(condition) #clip to the protected areas and no data\n",
    "    result = result.transpose('class', 'y', 'x') #transpose the data - rio expects it this way\n",
    "    return result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5351b2d-d19e-414e-a0db-b5ccbf8ba08e",
   "metadata": {},
   "source": [
    "Now we can actually run this. It should take about 30–60 seconds (to go through a 10 GB Sentinel-2 scene!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9c35f-74be-4300-89c1-5a8921707b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    predicted  = predict_xr(stack,geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ada586-1dcb-4e05-9084-ca1be0909a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb0bba3-788a-4015-bbe1-7d4ad0bd35c6",
   "metadata": {},
   "source": [
    "Now we can view our result. We will plot the probability that a pixel is covered in invasive Pine trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fb9bd-4239-4407-aa04-cb6de1f3d637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reproject\n",
    "predicted = predicted.rio.reproject(\"EPSG:4326\",nodata=np.nan)\n",
    "#select only pines\n",
    "predicted_plot = predicted.isel({'class':2})\n",
    "#set low probability to NaN\n",
    "predicted_plot = predicted_plot.where(predicted_plot > 0.5, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b09dbe-0de9-43ba-a9b6-e91f64e62237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot with a satellite basemap\n",
    "predicted_plot.hvplot(tiles=hv.element.tiles.EsriImagery(), \n",
    "                              project=True,clim=(0,1),\n",
    "                              cmap='magma',frame_width=800,data_aspect=1,alpha=0.7,title='Pine probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cc122-c454-429b-af9a-41d8a8c0582c",
   "metadata": {},
   "source": [
    "Lastly, we export to a geotiff. We can use rioxarray to do this. Now we can explore the map in our desktop GIS if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080a383-da80-4e9c-8ae4-8838aaa625fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted.rio.to_raster('gctwf_invasive.tiff',driver=\"COG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1308d71",
   "metadata": {},
   "source": [
    "This writes the file to the disk of our machine. If we are doing this on the cloud, it is wiser to write to cloud storage (S3), as this is much cheaper than local disk and almost infinitely scalable. We can also access this data from other machines on AWS, or share it with external collaborators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890cc7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "with fs.open(\"s3://my-bucket/invasive_data/gctwf_invasive.tiff\", \"wb\") as f:\n",
    "    predicted.rio.to_raster(f, driver=\"COG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4add9d8",
   "metadata": {},
   "source": [
    "### Write to Icechunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0f30d",
   "metadata": {},
   "source": [
    "We could also use Icechunk to store this data. Choosing between IceChunk/Zarr and GeoTIFF depends on your use case:\n",
    "\n",
    "GeoTIFF:\n",
    "- Single-file format, good for simple, static raster data\n",
    "- Limited to 2D or 3D arrays\n",
    "- Poor for very large datasets\n",
    "- No built-in versioning\n",
    "\n",
    "IceChunk/Zarr:\n",
    "- Chunked storage, enabling efficient partial data access\n",
    "- Scales to massive, multi-dimensional datasets\n",
    "- Cloud-native, parallel I/O for faster processing\n",
    "- Supports versioning (IceChunk) and collaborative workflows\n",
    "- Ideal for time-series analysis or complex data cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icechunk\n",
    "from icechunk.xarray import to_icechunk\n",
    "\n",
    "# 1. Configure S3 storage with anonymous access\n",
    "storage = icechunk.s3_storage(\n",
    "    bucket=\"my-bucket\",\n",
    "    prefix=\"invasive_data/gctwf_invasive\",\n",
    "    region=\"us-west-2\",    \n",
    "    anonymous=True,\n",
    ")\n",
    "\n",
    "# 2. Create a new repository\n",
    "repo = icechunk.Repository.create(storage)\n",
    "\n",
    "# 3. Open a writable session on the main branch\n",
    "session = repo.writable_session(\"main\")\n",
    "\n",
    "# 4. Write your xarray dataset\n",
    "to_icechunk(ds, session)\n",
    "\n",
    "# 5. Commit\n",
    "snapshot_id = session.commit(\"initial write\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c31fb8-2357-497a-9744-8d10a085c147",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "This lesson has borrowed heavily from the following resources, which are also a great place to learn more about handling large geospatial data in Python:\n",
    "\n",
    "- [The Carpentries Geospatial Python lesson by Ryan Avery](https://carpentries-incubator.github.io/geospatial-python/)\n",
    "- [The xarray user guide](https://docs.xarray.dev/en/stable/user-guide/index.html)\n",
    "- [An Introduction to Earth and Environmental Data Science](https://earth-env-data-science.github.io/intro.html)\n",
    "\n",
    "Another good place to start learning more is the [Cloud-Native Geospatial Foundation](https://cloudnativegeo.org/), which curates a community using and developing cloud-native geospatial tools.\n",
    "\n",
    "A deeper dive into using remote sensing for invasive species mapping can be found on the [NASA Applied Remote Sensing Training Program](https://www.earthdata.nasa.gov/learn/trainings/airborne-data-applications-invasive-species-mapping). This training contains an example based on this notebook that dives deeper into some of the machine learning concepts and data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
